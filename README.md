# ğŸ§  AmbedkarGPT â€” RAG-Based Q&A System  
### _AI Intern Hiring Assignment â€” Kalpit Pvt Ltd, UK_

This repository contains my solution for the **AI Intern Hiring â€“ Phase 1: Core Skills Evaluation**.  
The task was to build a complete **Retrieval-Augmented Generation (RAG)** pipeline using:

- **LangChain**
- **HuggingFace Embeddings (all-MiniLM-L6-v2)**
- **ChromaDB**
- **Ollama (Mistral 7B)**
- **Python 3.8+**

The system loads a short speech by **Dr. B.R. Ambedkar**, converts it into embeddings, retrieves relevant chunks for a question, and generates an answer using a local LLM â€” *all offline & free*.

---

## ğŸ“ **Project Structure**

```
project/
â”‚â”€â”€ assignment/                 
â”‚     â”‚â”€â”€ chroma_db/            # Auto-generated vector store (Chroma)
â”‚     â”‚â”€â”€ text_files/           
â”‚     â”‚     â””â”€â”€ speech.txt      # Input dataset (Ambedkar speech)
â”‚     â”‚â”€â”€ rag_ass.ipynb         # Main notebook with full implementation
â”‚
â”‚â”€â”€ requirements.txt            # All dependencies
â”‚â”€â”€ README.md                   # Documentation (this file)

```

---

## ğŸš€ **Features**

- End-to-end **RAG pipeline**
- Chunking of raw text  
- HuggingFace embeddings using MiniLM-L6-v2  
- Vector storage & retrieval with **ChromaDB**
- Answer generation using **Ollama + Mistral 7B**
- Fully offline â€” **no API keys, no cloud**
- Clean and modular implementation

---

## ğŸ› ï¸ **Tech Stack**

| Component        | Library/Tool |
|------------------|--------------|
| Programming Lang | Python 3.8+ |
| Framework        | LangChain |
| Vector DB        | ChromaDB |
| Embeddings       | HuggingFace MiniLM |
| LLM              | Ollama (Mistral 7B) |
| Notebook         | Jupyter Notebook |

---

## ğŸ“¦ **Installation & Setup**

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/<your-username>/AmbedkarGPT-Intern-Task.git
cd AmbedkarGPT-Intern-Task
```

---

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
```

#### **Windows**
```bash
venv\Scripts\activate
```

#### **Mac/Linux**
```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ¤– **Install Ollama (Required)**

Install Ollama:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

Pull Mistral:
```bash
ollama pull mistral
```

---

## â–¶ï¸ **Running the Project**

### **Run via Jupyter Notebook**
```bash
jupyter notebook rag_ass.ipynb
```

---

## ğŸ§  **How the RAG Pipeline Works**

1. **Load Data**  
   Loads the text file using `TextLoader`.

2. **Text Splitting**  
   Splits the speech into chunks using `RecursiveCharacterTextSplitter`.

3. **Embedding Creation**  
   Generates embeddings using  
   **sentence-transformers/all-MiniLM-L6-v2**

4. **Vector Store (ChromaDB)**  
   Stores embeddings locally for retrieval.

5. **Retrieval**  
   Finds the most relevant chunks based on the user question.

6. **LLM Response Generation**  
   Sends question + retrieved chunks to **Ollama Mistral**.

7. **Final Answer**  
   A clean natural-language answer is returned.

---

## ğŸ“„ **Example Query**

```
Question:
"What does Ambedkar say about caste and shastras?"

Answer:
(Generated by Mistral using retrieved context)
```

---

## ğŸ“š **Dataset**

The speech used is a short excerpt from **Annihilation of Caste** by Dr. B.R. Ambedkar.  
Included inside: `text_files/speech.txt`


## ğŸ‘¤ **Author**

**Srinandhini T**  
BS Programming & Data Science â€” IIT Madras  
AI/ML Engineer (Aspiring)

---
